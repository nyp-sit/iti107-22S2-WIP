{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dceb107",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107/blob/main/session-2/xception_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e",
   "metadata": {
    "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e"
   },
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Welcome to this week's programming exercise. In this week's exercises, we will learn how to improve our model performance using common tecniques such as data augmentation and transfer learning. \n",
    "\n",
    "Data augmentation is typically used when you have a small set of training samples. It allows you to increase your number of samples by generating artificial samples, either based on some random transformation of your existing samples, or by some statistical means. The larger training samples can help the model to generalize better. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a",
   "metadata": {
    "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264834c7-3b6d-4329-ab5e-0fbff76d2dfd",
   "metadata": {
    "id": "20393c0b-8e73-47d7-a371-70c61e58cbde"
   },
   "source": [
    "### Create train and validation dataset\n",
    "\n",
    "We will go ahead and prepare our train and validation dataset (the cats vs dogs dataset) as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131",
    "outputId": "b7b3cf18-c5a1-4264-c8d0-66b9ba2076b6"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "dataset_URL = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz'\n",
    "tf.keras.utils.get_file(origin=dataset_URL, extract=True, cache_dir='.')\n",
    "dataset_folder = os.path.join('datasets', 'cats_and_dogs_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78",
    "outputId": "7568f238-77d3-41ac-df60-a359663284b2"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "image_size = (128,128)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='binary'\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84c7f9-a8c2-4760-b044-72e0b452ce89",
   "metadata": {},
   "source": [
    "## Data Augmentation \n",
    "\n",
    "Since tensorflow 2.2, Keras introduces new types of layers for doing image data augmentation, such as Random Cropping, Random Flipping, etc. Previously, we have to depend on ImageDataGenerator() (which is a lot slower) to do so. \n",
    "\n",
    "In the code below, we create a Sequential model to add the image augmentation layer: `RandomRotation()`. The value `0.1' refers to the maximum rotation angle in both clock-wise and anti-clockwise direction. You can find out more info from the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b9baf-c172-406a-974f-efa66be6eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5353c9b-aa82-4907-8733-7989fe2f3c1a",
   "metadata": {},
   "source": [
    "To see the effects of data augmentation, let us apply our data_augmentation layer to a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bbb72b-72ac-42c3-a434-393f24d0d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = next(train_ds.take(1).as_numpy_iterator())\n",
    "sample_image = images[0]/255.\n",
    "plt.imshow(sample_image)\n",
    "sample_image = tf.expand_dims(sample_image, 0)\n",
    "print(sample_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70489a0-64a0-4608-a5cd-c4f45d1f060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "for i in range(8):\n",
    "    augmented_image = data_augmentation(sample_image)\n",
    "    ax = plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(augmented_image[0])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a0a66-b9f7-4da3-b93b-553a2bddec2b",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "Modify the code above to add in random Horizontal flip Choose the appropriate values for the contrast and cropping factor.\n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "```python\n",
    "    \n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomFlip(\"horizontal\")\n",
    "    ]\n",
    ")    \n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc6cf5-8b1b-4cdf-9cb8-bd31dad281a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Modify the code to add data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.RandomRotation(0.1),\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062e88a-78b5-42e2-9b28-ceb59a03f4ef",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Previously we have built the mini-Xception network and use it on our small cats and dogs dataset. It performs slightly better than the first simple model we built, but not much of an improvement. Here we will use the same network but adds in the data augmnetation to see if our model can be improved further. \n",
    "\n",
    "The following codes are same as previous xception network that you have coded. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c",
   "metadata": {
    "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c"
   },
   "outputs": [],
   "source": [
    "def xception_block(x, depth): \n",
    "    # save input to be used as skip connection\n",
    "    residual = x\n",
    "    \n",
    "    # add the first separable convolutional 2D layer (as well as the batch normalization and activation layer)\n",
    "    x = keras.layers.SeparableConv2D(depth, 3, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # add the second separable convolutional 2D layer (as well as the batch normalization BUT without activation layer)\n",
    "    x = keras.layers.SeparableConv2D(depth, 3, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # add the maxpooling 2d layer, with stride of 2\n",
    "    x = keras.layers.MaxPool2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # adjust the size and depth using 1x1 convolution to match the output from last maxpooling layer. Use strides=2 to match the output from maxpooling\n",
    "    residual = keras.layers.Conv2D(depth, 1, strides=2, padding='same')(residual)\n",
    "    \n",
    "    # add back the residual to the output from maxpooling layer\n",
    "    x = keras.layers.add( [x, residual] )\n",
    "    \n",
    "    # add the activation layer\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    return x # Set aside next residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca27e5-3101-4a5d-a844-a50310abe3dc",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise 2:**\n",
    "\n",
    "Modify the code in `make_model()` to apply data augmention layers you have created earlier. Where should you place your augmentation layer?  \n",
    "\n",
    "<details><summary>Click here for answer</summary>\n",
    "\n",
    "```python\n",
    "def make_model(input_shape, num_classes): \n",
    "    inputs = keras.Input(shape=input_shape)    \n",
    "    \n",
    "    ## Add your augmentation layers here !! \n",
    "    x = data_augmentation(inputs) \n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(inputs)\n",
    "\n",
    "    ## the rest of the codes.... \n",
    "    \n",
    "    return keras.Model(inputs, outputs)    \n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c",
   "metadata": {
    "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c"
   },
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes): \n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    ## Add your augmentation layers here !! \n",
    "    x = data_augmentation(inputs) \n",
    "\n",
    "    # add resclaing \n",
    "    x = keras.layers.Rescaling(1./255)(x)\n",
    "    \n",
    "    # Entry blocks\n",
    "\n",
    "    # 1st conv2d with strides = 2\n",
    "    x = keras.layers.Conv2D(32, 3, strides=2, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # 2nd conv2d with strides = 1\n",
    "    x = keras.layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # build a series of xception blocks with different depth\n",
    "    for depth in [128, 256, 512, 728]:\n",
    "        x = xception_block(x, depth)\n",
    "    \n",
    "    # add SeparableConv2D\n",
    "    x = keras.layers.SeparableConv2D(1024, 3, padding='same')(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # add Global Average Pooling layer before connecting to Dense layer \n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c",
    "outputId": "c13ed967-c654-4f6a-dd95-0802ea82ae40"
   },
   "outputs": [],
   "source": [
    "model = make_model(input_shape= image_size + (3,), num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef",
   "metadata": {
    "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Let's train our new model with the data augmentation layer.  We increase our training epochs to 50 to give our model more chances to see the augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d",
    "outputId": "a568d71b-7d6b-4b6e-99de-ab0dbd0250a1"
   },
   "outputs": [],
   "source": [
    "def create_tb_callback(): \n",
    "\n",
    "    import os\n",
    "    \n",
    "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "    def get_run_logdir():    # use a new directory for each run\n",
    "        \n",
    "        import time\n",
    "        \n",
    "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "        return os.path.join(root_logdir, run_id)\n",
    "\n",
    "    run_logdir = get_run_logdir()\n",
    "\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    return tb_callback\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"best_checkpoint\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "# compile our model with loss and optimizer \n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    train_ds, epochs=50, \n",
    "    validation_data=val_ds,\n",
    "    callbacks=[model_checkpoint_callback, create_tb_callback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab62a8-74e5-40c9-b46c-fa2105519d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir tb_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0985069-c506-479b-a84e-1e2e5d819de8",
   "metadata": {
    "id": "d0985069-c506-479b-a84e-1e2e5d819de8"
   },
   "outputs": [],
   "source": [
    "best_checkpoint = 'best_checkpoint'\n",
    "\n",
    "model.load_weights(best_checkpoint)\n",
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5274e-be88-4501-b48a-59015450305f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "xception.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
