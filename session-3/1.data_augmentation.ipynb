{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107/blob/main/session-3/1.data_augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e",
      "metadata": {
        "id": "dfc46a0d-4718-4a4f-9101-65ce70ff229e"
      },
      "source": [
        "# Data Augmentation\n",
        "\n",
        "Welcome to this week's programming exercise. In this week's exercises, we will learn how to improve our model performance using common tecniques such as data augmentation and transfer learning. \n",
        "\n",
        "Data augmentation is typically used when you have a small set of training samples. It allows you to increase your number of samples by generating artificial samples, either based on some random transformation of your existing samples, or by some statistical means. The larger training samples can help the model to generalize better. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a",
      "metadata": {
        "id": "152199e4-56a2-4e03-ba75-d4ad12e6312a"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264834c7-3b6d-4329-ab5e-0fbff76d2dfd",
      "metadata": {
        "id": "264834c7-3b6d-4329-ab5e-0fbff76d2dfd"
      },
      "source": [
        "### Create train and validation dataset\n",
        "\n",
        "We will be using the flower dataset from Tensorflow datasets. Let's go ahead and prepare our train and validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131",
      "metadata": {
        "id": "9d6c6756-58cd-442f-9c4e-88f31b0a7131"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "path_to_zip = tf.keras.utils.get_file(origin=dataset_url, extract=True, cache_dir='.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870d97af-0026-4e53-bb44-45902cf26808",
      "metadata": {
        "id": "870d97af-0026-4e53-bb44-45902cf26808"
      },
      "outputs": [],
      "source": [
        "dataset_folder = os.path.dirname(path_to_zip)\n",
        "dataset_folder = os.path.join(dataset_folder, 'flower_photos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78",
      "metadata": {
        "id": "4977bfe2-d84f-4512-9a70-462e57a8cd78"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "image_size = (128,128)\n",
        "\n",
        "# label_mode is set to 'int' as the dataset is multi-class\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_folder,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='int'\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_folder,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    label_mode='int'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c091d4-3a11-42c8-8d22-12d56fff7d5e",
      "metadata": {
        "id": "66c091d4-3a11-42c8-8d22-12d56fff7d5e"
      },
      "outputs": [],
      "source": [
        "print(val_ds.class_names)\n",
        "num_classes = len(val_ds.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f84c7f9-a8c2-4760-b044-72e0b452ce89",
      "metadata": {
        "id": "2f84c7f9-a8c2-4760-b044-72e0b452ce89"
      },
      "source": [
        "## Data Augmentation \n",
        "\n",
        "Since tensorflow 2.2, Keras introduces new types of layers for doing image data augmentation, such as Random Cropping, Random Flipping, etc. Previously, we have to depend on ImageDataGenerator() (which is a lot slower) to do so. \n",
        "\n",
        "In the code below, we create a Sequential model to add the image augmentation layer: `RandomRotation()`. The value `0.1' refers to the maximum rotation angle in both clock-wise and anti-clockwise direction. You can find out more info from the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6b9baf-c172-406a-974f-efa66be6eb25",
      "metadata": {
        "id": "0b6b9baf-c172-406a-974f-efa66be6eb25"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.RandomRotation(0.1),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5353c9b-aa82-4907-8733-7989fe2f3c1a",
      "metadata": {
        "id": "a5353c9b-aa82-4907-8733-7989fe2f3c1a"
      },
      "source": [
        "To see the effects of data augmentation, let us apply our data_augmentation layer to a sample image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7bbb72b-72ac-42c3-a434-393f24d0d0a0",
      "metadata": {
        "id": "b7bbb72b-72ac-42c3-a434-393f24d0d0a0"
      },
      "outputs": [],
      "source": [
        "images, _ = next(train_ds.take(1).as_numpy_iterator())\n",
        "sample_image = images[0]/255.\n",
        "plt.imshow(sample_image)\n",
        "sample_image = tf.expand_dims(sample_image, 0)\n",
        "print(sample_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e70489a0-64a0-4608-a5cd-c4f45d1f060f",
      "metadata": {
        "id": "e70489a0-64a0-4608-a5cd-c4f45d1f060f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "for i in range(8):\n",
        "    augmented_image = data_augmentation(sample_image)\n",
        "    ax = plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(augmented_image[0])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692a0a66-b9f7-4da3-b93b-553a2bddec2b",
      "metadata": {
        "id": "692a0a66-b9f7-4da3-b93b-553a2bddec2b"
      },
      "source": [
        "**Exercise 1:**\n",
        "\n",
        "Modify the code above to add in [random Horizontal flip](https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip). \n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "    \n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomFlip(\"horizontal\")\n",
        "    ]\n",
        ")    \n",
        "```\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57fc6cf5-8b1b-4cdf-9cb8-bd31dad281a9",
      "metadata": {
        "id": "57fc6cf5-8b1b-4cdf-9cb8-bd31dad281a9"
      },
      "outputs": [],
      "source": [
        "## TODO: Modify the code to add data augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.RandomRotation(0.1)\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d062e88a-78b5-42e2-9b28-ceb59a03f4ef",
      "metadata": {
        "id": "d062e88a-78b5-42e2-9b28-ceb59a03f4ef"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "We will use the mini Xception network that we built in previous lab and use it to classify our flow dataset. The codes for xception block is given below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c",
      "metadata": {
        "id": "b79f86c8-54bb-4bdc-b4c6-31344cbfb16c"
      },
      "outputs": [],
      "source": [
        "def xception_block(x, depth): \n",
        "    \n",
        "    residual = x\n",
        "    \n",
        "    x = keras.layers.SeparableConv2D(depth, 3, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    x = keras.layers.SeparableConv2D(depth, 3, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    \n",
        "    x = keras.layers.MaxPool2D(3, strides=2, padding='same')(x)\n",
        "    \n",
        "    residual = keras.layers.Conv2D(depth, 1, strides=2, padding='same')(residual)\n",
        "    \n",
        "    x = keras.layers.add( [x, residual] )\n",
        "    \n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    return x "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cca27e5-3101-4a5d-a844-a50310abe3dc",
      "metadata": {
        "id": "2cca27e5-3101-4a5d-a844-a50310abe3dc"
      },
      "source": [
        "\n",
        "**Exercise 2:**\n",
        "\n",
        "Modify the code in `make_model()` to apply data augmention layers you have created earlier. Where should you place your augmentation layer?  \n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "\n",
        "```python\n",
        "def make_model(input_shape, num_classes): \n",
        "    inputs = keras.Input(shape=input_shape)    \n",
        "    \n",
        "    ## Add your augmentation layers here !! \n",
        "    x = data_augmentation(inputs) \n",
        "\n",
        "    x = layers.Rescaling(1.0 / 255)(x)\n",
        "\n",
        "    ## the rest of the codes.... \n",
        "    \n",
        "    return keras.Model(inputs, outputs)    \n",
        "```\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c",
      "metadata": {
        "id": "70c4052d-f8dc-4602-a61f-fd648b9ea40c"
      },
      "outputs": [],
      "source": [
        "##TODO: Modify the code below to add in the data augmentation layer\n",
        "def make_model(input_shape, num_classes): \n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "\n",
        "    # add resclaing \n",
        "    x = keras.layers.Rescaling(1./255)(inputs)\n",
        "    \n",
        "    # 1st conv2d with strides = 2\n",
        "    x = keras.layers.Conv2D(32, 3, strides=2, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "\n",
        "    # 2nd conv2d with strides = 1\n",
        "    x = keras.layers.Conv2D(64, 3, strides=1, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    # build a series of xception blocks with different depth\n",
        "    for depth in [128, 256, 512, 728]:\n",
        "        x = xception_block(x, depth)\n",
        "    \n",
        "    # add SeparableConv2D\n",
        "    x = keras.layers.SeparableConv2D(1024, 3, padding='same')(x)\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    x = keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    # add Global Average Pooling layer before connecting to Dense layer \n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    x = keras.layers.Dropout(0.5)(x)\n",
        "    \n",
        "    outputs = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    return keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c",
      "metadata": {
        "id": "fa7bca3d-037a-4c1e-bc96-8afbcda7053c"
      },
      "outputs": [],
      "source": [
        "model = make_model(input_shape= image_size + (3,), num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef",
      "metadata": {
        "id": "b848e43d-38e2-4fe8-a73b-2eccc29777ef"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Let's train our new model with the data augmentation layer.  We increase our training epochs to 50 to give our model more chances to see the augmented images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d",
      "metadata": {
        "id": "f19cb509-ba47-4abe-8888-6bfb01cf493d"
      },
      "outputs": [],
      "source": [
        "def create_tb_callback(): \n",
        "\n",
        "    import os\n",
        "    \n",
        "    root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
        "\n",
        "    def get_run_logdir():    # use a new directory for each run\n",
        "        \n",
        "        import time\n",
        "        \n",
        "        run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "        return os.path.join(root_logdir, run_id)\n",
        "\n",
        "    run_logdir = get_run_logdir()\n",
        "\n",
        "    tb_callback = tf.keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "    return tb_callback\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"best_checkpoint\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "# compile our model with loss and optimizer \n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    train_ds, epochs=50, \n",
        "    validation_data=val_ds,\n",
        "    callbacks=[model_checkpoint_callback, create_tb_callback()]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cab62a8-74e5-40c9-b46c-fa2105519d89",
      "metadata": {
        "id": "2cab62a8-74e5-40c9-b46c-fa2105519d89"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0985069-c506-479b-a84e-1e2e5d819de8",
      "metadata": {
        "id": "d0985069-c506-479b-a84e-1e2e5d819de8"
      },
      "outputs": [],
      "source": [
        "best_checkpoint = 'best_checkpoint'\n",
        "\n",
        "model.load_weights(best_checkpoint)\n",
        "model.evaluate(val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "You can try to add in more data augmentation e.g. random cropping, or changing the contrast. \n",
        "Does additional augmentation improve your model?  What do you observe? \n",
        "\n",
        "\n",
        "<details><summary>Click here for answer</summary>\n",
        "Our model is still clearly overfitting, even though we have used data augmentation. The augmented images are still heavily correlated, since they come from a small number of original images -- we cannot produce new information, we can only remix existing information. As next step to improve our accuracy on this problem, we will have to leverage transfer learning using pre-trained model, which will be the focus of the lesson.\n",
        "</details>"
      ],
      "metadata": {
        "id": "0aMisZ4K7sWy"
      },
      "id": "0aMisZ4K7sWy"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}