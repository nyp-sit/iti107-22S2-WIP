{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2c4560",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107/blob/main/session-3/3.fine-tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b8183-8ef0-4664-813f-6a635bda0f15",
   "metadata": {
    "id": "ce6b8183-8ef0-4664-813f-6a635bda0f15"
   },
   "source": [
    "## Fine-tuning\n",
    "\n",
    "Another widely used transfer learning technique is _fine-tuning_. \n",
    "Fine-tuning involves unfreezing a few of the top layers \n",
    "of a frozen model base used for feature extraction, and jointly training both the newly added part of the model (in our case, the \n",
    "fully-connected classifier) and these unfrozen top layers. This is called \"fine-tuning\" because it slightly adjusts the more abstract \n",
    "representations of the model being reused, in order to make them more relevant for the problem at hand.\n",
    "\n",
    "\n",
    "\n",
    "![fine-tuning VGG16](https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/iti107/resources/vgg16_fine_tuning.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "768ead86-19a3-4908-be5b-57538c555a19",
   "metadata": {
    "id": "768ead86-19a3-4908-be5b-57538c555a19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markk\\miniconda3\\envs\\dlenv\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35f9d10-815d-4b80-9cc5-b6c29cd2010f",
   "metadata": {
    "id": "toPgcpoW4HIm"
   },
   "source": [
    "## Creating Datasets\n",
    "\n",
    "We will setup our training and validation dataset as we did in earlier exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc8d2e8a-b80a-410a-afb7-b7534a83af77",
   "metadata": {
    "id": "dc8d2e8a-b80a-410a-afb7-b7534a83af77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz\n",
      "67043328/67041740 [==============================] - 3s 0us/step\n",
      "67051520/67041740 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "dataset_URL = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz'\n",
    "tf.keras.utils.get_file(origin=dataset_URL, extract=True, cache_dir='.')\n",
    "dataset_folder = os.path.join('datasets', 'cats_and_dogs_subset')\n",
    "# dataset_URL = 'https://nyp-aicourse.s3.ap-southeast-1.amazonaws.com/iti107/datasets/emotions_dataset_jpg.zip'\n",
    "# path_to_zip= keras.utils.get_file('emotions_dataset_jpg.zip', origin=dataset_URL, extract=True, cache_dir='.')\n",
    "# print(path_to_zip)\n",
    "# dataset_folder = os.path.dirname(path_to_zip)\n",
    "# dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
    "# path_to_zip = tf.keras.utils.get_file(origin=dataset_url, extract=True, cache_dir='.')\n",
    "# dataset_folder = os.path.dirname(path_to_zip)\n",
    "# dataset_folder = os.path.join(dataset_folder, 'flower_photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "208febe1-3fdf-41e3-999c-3fac7e70f007",
   "metadata": {
    "id": "208febe1-3fdf-41e3-999c-3fac7e70f007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 files belonging to 2 classes.\n",
      "Using 2400 files for training.\n",
      "Found 3000 files belonging to 2 classes.\n",
      "Using 600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "image_size = (128,128)\n",
    "label_mode = 'binary'\n",
    "num_classes = 2\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_folder,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=label_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f27d8-f9c2-4168-969c-2b5c59eccb35",
   "metadata": {
    "id": "790141c4-2bee-4431-8449-204417495a64"
   },
   "source": [
    "## Transfer Learning Workflow \n",
    "\n",
    "It was necessary to freeze the convolution base before training a randomly initialized classifier top. If the classifier wasn't already trained, then the error signal propagating through the network during training would be too large, and the representations previously learned by the layers being fine-tuned would be destroyed. Thus the steps for fine-tuning a network are as follow:\n",
    "\n",
    "1. Add your custom network on top of an already trained base network.\n",
    "2. Freeze the convolutional base network.\n",
    "3. Train the classification top you added.\n",
    "4. Unfreeze some layers in the base network.\n",
    "5. Jointly train both these layers and the part you added.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdeee29-8fee-4f03-93c9-8257f28403a1",
   "metadata": {},
   "source": [
    "#### BatchNormalization layer \n",
    "\n",
    "Many CNN models contain BatchNormalization layers. \n",
    "BatchNormalization contains 2 non-trainable variables that keep track of the mean and variance of the inputs. These variables are updated during training time. Here are a few things to note when fine-tuning model with BatchNormalization layers: \n",
    "- When you set `bn_layer.trainable = False`, the BatchNormalization layer will run in inference mode, and will not update its mean & variance statistics. \n",
    "- When you unfreeze a model that contains BatchNormalization layers in order to do fine-tuning, you should keep the BatchNormalization layers in inference mode by passing `training=False` when calling the base model. Otherwise the updates applied to the non-trainable weights will suddenly destroy what the model has learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0d8765-9894-422a-8c70-85b023517f86",
   "metadata": {},
   "source": [
    "## Build our Model \n",
    "\n",
    "We will now construct our model: a convolutional base (initialized with pre-trained weights) and our own classification head (initialized with random weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7689d158-edd7-4015-9ce8-29fc8f87ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.RandomRotation(0.1),\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "RB9VSinUyvhV",
   "metadata": {
    "id": "RB9VSinUyvhV"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained model \n",
    "base_model = keras.applications.EfficientNetB0(input_shape=image_size + (3,),\n",
    "                                         include_top=False,\n",
    "                                         weights='imagenet')\n",
    "\n",
    "## This is not necessary as it is just a passthrough. EfficientNet model includes the rescaling layer that preprocess the input\n",
    "## refer to https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/preprocess_input\n",
    "preprocess_input_fn = keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "# freeze the base layer \n",
    "base_model.trainable = False\n",
    "\n",
    "# Add input layer \n",
    "inputs = keras.layers.Input(shape=image_size+(3,))\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "# Add preprocessing layer\n",
    "\n",
    "## This is not necessary as it is just a passthrough. EfficientNet model includes the rescaling layer that preprocess the input\n",
    "## refer to https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet/preprocess_input\n",
    "x = preprocess_input_fn(x)\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Add our classification head\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(rate=0.5)(x)\n",
    "#x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
    "#x = keras.layers.Dropout(rate=0.5)(x)\n",
    "\n",
    "# outputs = keras.layers.Dense(units=1, activation=\"softmax\")(x)\n",
    "outputs = keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", \n",
    "                  optimizer=keras.optimizers.Adam(learning_rate=base_learning_rate), \n",
    "                  metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70615d42-c371-476f-aa1e-a714ff8f8a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'dogs']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0UVNujET2sho",
   "metadata": {
    "id": "0UVNujET2sho"
   },
   "source": [
    "Let's confirm all the layers of convolutional base are frozen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42c15c81-d461-4881-b6c8-ae948e2361ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer name = input_13, trainable=False\n",
      "layer name = rescaling_6, trainable=False\n",
      "layer name = normalization_6, trainable=False\n",
      "layer name = stem_conv_pad, trainable=False\n",
      "layer name = stem_conv, trainable=False\n",
      "layer name = stem_bn, trainable=False\n",
      "layer name = stem_activation, trainable=False\n",
      "layer name = block1a_dwconv, trainable=False\n",
      "layer name = block1a_bn, trainable=False\n",
      "layer name = block1a_activation, trainable=False\n",
      "layer name = block1a_se_squeeze, trainable=False\n",
      "layer name = block1a_se_reshape, trainable=False\n",
      "layer name = block1a_se_reduce, trainable=False\n",
      "layer name = block1a_se_expand, trainable=False\n",
      "layer name = block1a_se_excite, trainable=False\n",
      "layer name = block1a_project_conv, trainable=False\n",
      "layer name = block1a_project_bn, trainable=False\n",
      "layer name = block2a_expand_conv, trainable=False\n",
      "layer name = block2a_expand_bn, trainable=False\n",
      "layer name = block2a_expand_activation, trainable=False\n",
      "layer name = block2a_dwconv_pad, trainable=False\n",
      "layer name = block2a_dwconv, trainable=False\n",
      "layer name = block2a_bn, trainable=False\n",
      "layer name = block2a_activation, trainable=False\n",
      "layer name = block2a_se_squeeze, trainable=False\n",
      "layer name = block2a_se_reshape, trainable=False\n",
      "layer name = block2a_se_reduce, trainable=False\n",
      "layer name = block2a_se_expand, trainable=False\n",
      "layer name = block2a_se_excite, trainable=False\n",
      "layer name = block2a_project_conv, trainable=False\n",
      "layer name = block2a_project_bn, trainable=False\n",
      "layer name = block2b_expand_conv, trainable=False\n",
      "layer name = block2b_expand_bn, trainable=False\n",
      "layer name = block2b_expand_activation, trainable=False\n",
      "layer name = block2b_dwconv, trainable=False\n",
      "layer name = block2b_bn, trainable=False\n",
      "layer name = block2b_activation, trainable=False\n",
      "layer name = block2b_se_squeeze, trainable=False\n",
      "layer name = block2b_se_reshape, trainable=False\n",
      "layer name = block2b_se_reduce, trainable=False\n",
      "layer name = block2b_se_expand, trainable=False\n",
      "layer name = block2b_se_excite, trainable=False\n",
      "layer name = block2b_project_conv, trainable=False\n",
      "layer name = block2b_project_bn, trainable=False\n",
      "layer name = block2b_drop, trainable=False\n",
      "layer name = block2b_add, trainable=False\n",
      "layer name = block3a_expand_conv, trainable=False\n",
      "layer name = block3a_expand_bn, trainable=False\n",
      "layer name = block3a_expand_activation, trainable=False\n",
      "layer name = block3a_dwconv_pad, trainable=False\n",
      "layer name = block3a_dwconv, trainable=False\n",
      "layer name = block3a_bn, trainable=False\n",
      "layer name = block3a_activation, trainable=False\n",
      "layer name = block3a_se_squeeze, trainable=False\n",
      "layer name = block3a_se_reshape, trainable=False\n",
      "layer name = block3a_se_reduce, trainable=False\n",
      "layer name = block3a_se_expand, trainable=False\n",
      "layer name = block3a_se_excite, trainable=False\n",
      "layer name = block3a_project_conv, trainable=False\n",
      "layer name = block3a_project_bn, trainable=False\n",
      "layer name = block3b_expand_conv, trainable=False\n",
      "layer name = block3b_expand_bn, trainable=False\n",
      "layer name = block3b_expand_activation, trainable=False\n",
      "layer name = block3b_dwconv, trainable=False\n",
      "layer name = block3b_bn, trainable=False\n",
      "layer name = block3b_activation, trainable=False\n",
      "layer name = block3b_se_squeeze, trainable=False\n",
      "layer name = block3b_se_reshape, trainable=False\n",
      "layer name = block3b_se_reduce, trainable=False\n",
      "layer name = block3b_se_expand, trainable=False\n",
      "layer name = block3b_se_excite, trainable=False\n",
      "layer name = block3b_project_conv, trainable=False\n",
      "layer name = block3b_project_bn, trainable=False\n",
      "layer name = block3b_drop, trainable=False\n",
      "layer name = block3b_add, trainable=False\n",
      "layer name = block4a_expand_conv, trainable=False\n",
      "layer name = block4a_expand_bn, trainable=False\n",
      "layer name = block4a_expand_activation, trainable=False\n",
      "layer name = block4a_dwconv_pad, trainable=False\n",
      "layer name = block4a_dwconv, trainable=False\n",
      "layer name = block4a_bn, trainable=False\n",
      "layer name = block4a_activation, trainable=False\n",
      "layer name = block4a_se_squeeze, trainable=False\n",
      "layer name = block4a_se_reshape, trainable=False\n",
      "layer name = block4a_se_reduce, trainable=False\n",
      "layer name = block4a_se_expand, trainable=False\n",
      "layer name = block4a_se_excite, trainable=False\n",
      "layer name = block4a_project_conv, trainable=False\n",
      "layer name = block4a_project_bn, trainable=False\n",
      "layer name = block4b_expand_conv, trainable=False\n",
      "layer name = block4b_expand_bn, trainable=False\n",
      "layer name = block4b_expand_activation, trainable=False\n",
      "layer name = block4b_dwconv, trainable=False\n",
      "layer name = block4b_bn, trainable=False\n",
      "layer name = block4b_activation, trainable=False\n",
      "layer name = block4b_se_squeeze, trainable=False\n",
      "layer name = block4b_se_reshape, trainable=False\n",
      "layer name = block4b_se_reduce, trainable=False\n",
      "layer name = block4b_se_expand, trainable=False\n",
      "layer name = block4b_se_excite, trainable=False\n",
      "layer name = block4b_project_conv, trainable=False\n",
      "layer name = block4b_project_bn, trainable=False\n",
      "layer name = block4b_drop, trainable=False\n",
      "layer name = block4b_add, trainable=False\n",
      "layer name = block4c_expand_conv, trainable=False\n",
      "layer name = block4c_expand_bn, trainable=False\n",
      "layer name = block4c_expand_activation, trainable=False\n",
      "layer name = block4c_dwconv, trainable=False\n",
      "layer name = block4c_bn, trainable=False\n",
      "layer name = block4c_activation, trainable=False\n",
      "layer name = block4c_se_squeeze, trainable=False\n",
      "layer name = block4c_se_reshape, trainable=False\n",
      "layer name = block4c_se_reduce, trainable=False\n",
      "layer name = block4c_se_expand, trainable=False\n",
      "layer name = block4c_se_excite, trainable=False\n",
      "layer name = block4c_project_conv, trainable=False\n",
      "layer name = block4c_project_bn, trainable=False\n",
      "layer name = block4c_drop, trainable=False\n",
      "layer name = block4c_add, trainable=False\n",
      "layer name = block5a_expand_conv, trainable=False\n",
      "layer name = block5a_expand_bn, trainable=False\n",
      "layer name = block5a_expand_activation, trainable=False\n",
      "layer name = block5a_dwconv, trainable=False\n",
      "layer name = block5a_bn, trainable=False\n",
      "layer name = block5a_activation, trainable=False\n",
      "layer name = block5a_se_squeeze, trainable=False\n",
      "layer name = block5a_se_reshape, trainable=False\n",
      "layer name = block5a_se_reduce, trainable=False\n",
      "layer name = block5a_se_expand, trainable=False\n",
      "layer name = block5a_se_excite, trainable=False\n",
      "layer name = block5a_project_conv, trainable=False\n",
      "layer name = block5a_project_bn, trainable=False\n",
      "layer name = block5b_expand_conv, trainable=False\n",
      "layer name = block5b_expand_bn, trainable=False\n",
      "layer name = block5b_expand_activation, trainable=False\n",
      "layer name = block5b_dwconv, trainable=False\n",
      "layer name = block5b_bn, trainable=False\n",
      "layer name = block5b_activation, trainable=False\n",
      "layer name = block5b_se_squeeze, trainable=False\n",
      "layer name = block5b_se_reshape, trainable=False\n",
      "layer name = block5b_se_reduce, trainable=False\n",
      "layer name = block5b_se_expand, trainable=False\n",
      "layer name = block5b_se_excite, trainable=False\n",
      "layer name = block5b_project_conv, trainable=False\n",
      "layer name = block5b_project_bn, trainable=False\n",
      "layer name = block5b_drop, trainable=False\n",
      "layer name = block5b_add, trainable=False\n",
      "layer name = block5c_expand_conv, trainable=False\n",
      "layer name = block5c_expand_bn, trainable=False\n",
      "layer name = block5c_expand_activation, trainable=False\n",
      "layer name = block5c_dwconv, trainable=False\n",
      "layer name = block5c_bn, trainable=False\n",
      "layer name = block5c_activation, trainable=False\n",
      "layer name = block5c_se_squeeze, trainable=False\n",
      "layer name = block5c_se_reshape, trainable=False\n",
      "layer name = block5c_se_reduce, trainable=False\n",
      "layer name = block5c_se_expand, trainable=False\n",
      "layer name = block5c_se_excite, trainable=False\n",
      "layer name = block5c_project_conv, trainable=False\n",
      "layer name = block5c_project_bn, trainable=False\n",
      "layer name = block5c_drop, trainable=False\n",
      "layer name = block5c_add, trainable=False\n",
      "layer name = block6a_expand_conv, trainable=False\n",
      "layer name = block6a_expand_bn, trainable=False\n",
      "layer name = block6a_expand_activation, trainable=False\n",
      "layer name = block6a_dwconv_pad, trainable=False\n",
      "layer name = block6a_dwconv, trainable=False\n",
      "layer name = block6a_bn, trainable=False\n",
      "layer name = block6a_activation, trainable=False\n",
      "layer name = block6a_se_squeeze, trainable=False\n",
      "layer name = block6a_se_reshape, trainable=False\n",
      "layer name = block6a_se_reduce, trainable=False\n",
      "layer name = block6a_se_expand, trainable=False\n",
      "layer name = block6a_se_excite, trainable=False\n",
      "layer name = block6a_project_conv, trainable=False\n",
      "layer name = block6a_project_bn, trainable=False\n",
      "layer name = block6b_expand_conv, trainable=False\n",
      "layer name = block6b_expand_bn, trainable=False\n",
      "layer name = block6b_expand_activation, trainable=False\n",
      "layer name = block6b_dwconv, trainable=False\n",
      "layer name = block6b_bn, trainable=False\n",
      "layer name = block6b_activation, trainable=False\n",
      "layer name = block6b_se_squeeze, trainable=False\n",
      "layer name = block6b_se_reshape, trainable=False\n",
      "layer name = block6b_se_reduce, trainable=False\n",
      "layer name = block6b_se_expand, trainable=False\n",
      "layer name = block6b_se_excite, trainable=False\n",
      "layer name = block6b_project_conv, trainable=False\n",
      "layer name = block6b_project_bn, trainable=False\n",
      "layer name = block6b_drop, trainable=False\n",
      "layer name = block6b_add, trainable=False\n",
      "layer name = block6c_expand_conv, trainable=False\n",
      "layer name = block6c_expand_bn, trainable=False\n",
      "layer name = block6c_expand_activation, trainable=False\n",
      "layer name = block6c_dwconv, trainable=False\n",
      "layer name = block6c_bn, trainable=False\n",
      "layer name = block6c_activation, trainable=False\n",
      "layer name = block6c_se_squeeze, trainable=False\n",
      "layer name = block6c_se_reshape, trainable=False\n",
      "layer name = block6c_se_reduce, trainable=False\n",
      "layer name = block6c_se_expand, trainable=False\n",
      "layer name = block6c_se_excite, trainable=False\n",
      "layer name = block6c_project_conv, trainable=False\n",
      "layer name = block6c_project_bn, trainable=False\n",
      "layer name = block6c_drop, trainable=False\n",
      "layer name = block6c_add, trainable=False\n",
      "layer name = block6d_expand_conv, trainable=False\n",
      "layer name = block6d_expand_bn, trainable=False\n",
      "layer name = block6d_expand_activation, trainable=False\n",
      "layer name = block6d_dwconv, trainable=False\n",
      "layer name = block6d_bn, trainable=False\n",
      "layer name = block6d_activation, trainable=False\n",
      "layer name = block6d_se_squeeze, trainable=False\n",
      "layer name = block6d_se_reshape, trainable=False\n",
      "layer name = block6d_se_reduce, trainable=False\n",
      "layer name = block6d_se_expand, trainable=False\n",
      "layer name = block6d_se_excite, trainable=False\n",
      "layer name = block6d_project_conv, trainable=False\n",
      "layer name = block6d_project_bn, trainable=False\n",
      "layer name = block6d_drop, trainable=False\n",
      "layer name = block6d_add, trainable=False\n",
      "layer name = block7a_expand_conv, trainable=False\n",
      "layer name = block7a_expand_bn, trainable=False\n",
      "layer name = block7a_expand_activation, trainable=False\n",
      "layer name = block7a_dwconv, trainable=False\n",
      "layer name = block7a_bn, trainable=False\n",
      "layer name = block7a_activation, trainable=False\n",
      "layer name = block7a_se_squeeze, trainable=False\n",
      "layer name = block7a_se_reshape, trainable=False\n",
      "layer name = block7a_se_reduce, trainable=False\n",
      "layer name = block7a_se_expand, trainable=False\n",
      "layer name = block7a_se_excite, trainable=False\n",
      "layer name = block7a_project_conv, trainable=False\n",
      "layer name = block7a_project_bn, trainable=False\n",
      "layer name = top_conv, trainable=False\n",
      "layer name = top_bn, trainable=False\n",
      "layer name = top_activation, trainable=False\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers:\n",
    "    print(f'layer name = {layer.name}, trainable={layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3277a092-38c6-48fd-a731-90a38a716911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "\n",
    "for layer in base_model.layers: \n",
    "    if layer.name == 'block7a_expand_conv': \n",
    "        print(index)\n",
    "        break\n",
    "    index += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q418z8cI3V-O",
   "metadata": {
    "id": "Q418z8cI3V-O"
   },
   "source": [
    "Let's print out the model summary and see how many trainable weights. We can see that we only 1,281 trainable weights (parameters), coming from the classification head that put on top of the convolutional base. (For comparison, a EfficientNetB0 has total of 4,049,571 weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ZkwKVe2_2_qF",
   "metadata": {
    "id": "ZkwKVe2_2_qF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.preprocessing.image_preprocessing.RandomRotation at 0x23c175ffca0>,\n",
       " <keras.layers.preprocessing.image_preprocessing.RandomFlip at 0x23c13436a90>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3d8db2b-5e00-4a3f-97e4-bf68cd138b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 4, 4, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 1281      \n",
      "=================================================================\n",
      "Total params: 4,050,852\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZSyhl8et47AV",
   "metadata": {
    "id": "ZSyhl8et47AV"
   },
   "source": [
    "## Train the classification head \n",
    "\n",
    "We will go ahead and train our classification head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cqSDQ4gP5HEO",
   "metadata": {
    "id": "cqSDQ4gP5HEO"
   },
   "outputs": [],
   "source": [
    "# create model checkpoint callback to save the best model checkpoint\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"best_checkpoint\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, \n",
    "          epochs=50, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "xjZaiOhQH8yy",
   "metadata": {
    "id": "xjZaiOhQH8yy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 4s 100ms/step - loss: 0.0917 - accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09174549579620361, 0.9750000238418579]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('best_checkpoint')\n",
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37688aa-d4c6-4e94-b9c8-fd9649852bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"frozenbase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872eee3b-4abd-4601-acfd-3a6dbf7c4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"frozenbase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f21fa0-7604-431e-8aec-a90af184370d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d426c-7666-47b1-84a6-485826b79641",
   "metadata": {
    "id": "172d426c-7666-47b1-84a6-485826b79641"
   },
   "source": [
    "Now we have our classification layers trained, let's start to unfreeze some top layers of the convolutional base to fine tune the weights. \n",
    "We will fine-tune the last 3 convolutional layers, which means that all layers up until `block4_pool` should be frozen, and the layers \n",
    "`block5_conv1`, `block5_conv2` and `block5_conv3` should be trainable.\n",
    "\n",
    "Why not fine-tune more layers? Why not fine-tune the entire convolutional base? We could. However, we need to consider that:\n",
    "\n",
    "* Earlier layers in the convolutional base encode more generic, reusable features, while layers higher up encode more specialized features. It is \n",
    "more useful to fine-tune the more specialized features, as these are the ones that need to be repurposed on our new problem. There would \n",
    "be fast-decreasing returns in fine-tuning lower layers.\n",
    "* The more parameters we are training, the more we are at risk of overfitting. The convolutional base has 15M parameters, so it would be \n",
    "risky to attempt to train it on our small dataset.\n",
    "\n",
    "Thus, in our situation, it is a good strategy to only fine-tune the top 2 to 3 layers in the convolutional base.\n",
    "\n",
    "Let's set this up, we will unfreeze our `base_model`, \n",
    "and then freeze individual layers inside of it, except the last 3 layers. \n",
    "\n",
    "Do a model ``summary()`` and you will see now that the number of trainable weights are now 7,079,424 (around 7 millions), much less than previously, because all the layers are frozen except the last 3 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "690283a8-4c53-4293-b8f2-c0685d8031aa",
   "metadata": {
    "id": "690283a8-4c53-4293-b8f2-c0685d8031aa"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "# for layer in base_model.layers[:221]:\n",
    "#     layer.trainable = False\n",
    "for layer in base_model.layers[:221]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c83f93-c35c-44c5-9925-f24191c917ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wWXyo3n5903l",
   "metadata": {
    "id": "wWXyo3n5903l"
   },
   "source": [
    "Let us examine model summary again. We can see now that we have more trainable weights 7,342,593 compared to previously 263,169."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8uq86nMv-HxP",
   "metadata": {
    "id": "8uq86nMv-HxP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "efficientnetb0 (Functional)  (None, 4, 4, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 1281      \n",
      "=================================================================\n",
      "Total params: 4,050,852\n",
      "Trainable params: 1,130,673\n",
      "Non-trainable params: 2,920,179\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdZPk1Ay80r_",
   "metadata": {
    "id": "bdZPk1Ay80r_"
   },
   "source": [
    "As you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage as we do not want to make too drastic changes to the weights in the convolutional layers under fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc1da460-3c8a-40f3-a9e5-14c7b832ef79",
   "metadata": {
    "id": "bc1da460-3c8a-40f3-a9e5-14c7b832ef79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 27s 151ms/step - loss: 0.1221 - accuracy: 0.9504 - val_loss: 0.0736 - val_accuracy: 0.9650\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0971 - accuracy: 0.9658 - val_loss: 0.0689 - val_accuracy: 0.9733\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 21s 142ms/step - loss: 0.0726 - accuracy: 0.9733 - val_loss: 0.0661 - val_accuracy: 0.9700\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0610 - accuracy: 0.9767 - val_loss: 0.0665 - val_accuracy: 0.9733\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0497 - accuracy: 0.9804 - val_loss: 0.0701 - val_accuracy: 0.9733\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0421 - accuracy: 0.9846 - val_loss: 0.0717 - val_accuracy: 0.9717\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 21s 143ms/step - loss: 0.0390 - accuracy: 0.9862 - val_loss: 0.0703 - val_accuracy: 0.9700\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0314 - accuracy: 0.9875 - val_loss: 0.0717 - val_accuracy: 0.9733\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0773 - val_accuracy: 0.9733\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0764 - val_accuracy: 0.9717\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0263 - accuracy: 0.9904 - val_loss: 0.0835 - val_accuracy: 0.9733\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 21s 142ms/step - loss: 0.0194 - accuracy: 0.9929 - val_loss: 0.0846 - val_accuracy: 0.9717\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 21s 141ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.0813 - val_accuracy: 0.9717\n",
      "Epoch 14/20\n",
      " 41/150 [=======>......................] - ETA: 12s - loss: 0.0085 - accuracy: 0.9970"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mfinetune_learning_rate),\n\u001b[0;32m      5\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# model.compile(loss=\"sparse_categorical_crossentropy\",\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#               optimizer=keras.optimizers.Adam(learning_rate=finetune_learning_rate),\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#               metrics=[\"accuracy\"])\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dlenv\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dlenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dlenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\dlenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "finetune_learning_rate = base_learning_rate / 10.\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=finetune_learning_rate),\n",
    "              metrics=[\"accuracy\"])\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#               optimizer=keras.optimizers.Adam(learning_rate=finetune_learning_rate),\n",
    "#               metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=20,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2496b41f-63bd-42ca-aa6a-923a6588d4d8",
   "metadata": {
    "id": "2496b41f-63bd-42ca-aa6a-923a6588d4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 2s 31ms/step - loss: 0.2563 - accuracy: 0.9319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2562572956085205, 0.9318801164627075]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('best_checkpoint')\n",
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RKt9lTt3_qYi",
   "metadata": {
    "id": "RKt9lTt3_qYi"
   },
   "source": [
    "**Question:**\n",
    "\n",
    "Is our fine-tuned model performing better or worse than the previous model?\n",
    "\n",
    "Provide a possible explanation to your observation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c92a10-f21a-46a3-945c-dc6a7f3e9357",
   "metadata": {},
   "outputs": [],
   "source": [
    "**Exercise:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62fcec-a85e-4ce1-8c99-ffbc7924b062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908f9a71-a6b5-4852-b98a-016f6c8be5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2bfdd-516f-47eb-97ad-27e9f45263f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "3.fine-tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
