{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train convnet with custom data",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107/blob/main/session-1/train_convnet_with_custom_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6gHiH-I7uFa"
      },
      "source": [
        "# Exercise: Using Convolutional Neural Network for Custom Data\n",
        "\n",
        "In this exercise, you will apply what you learnt in the previous lab and apply it on a more realistic dataset (as compared to the toy dataset such as Fashion MNIST). Also, you will learn to create `tf.data.Dataset` and use them for training.\n",
        "\n",
        "We will be using a smaller subset of the original [Cats vs. Dogs dataset] (https://www.kaggle.com/c/dogs-vs-cats/data) from Kaggle. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvWMjo-aEx9I"
      },
      "source": [
        "## Download the dataset\n",
        "\n",
        "Download the dataset from https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/cats_and_dogs_subset.tar.gz and unzip into a folder. You can use [tf.keras.utils.get_file()](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) which will download and unzip for you, or just run wget and unzip using bash.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQw0U8lFEx9I"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0tFgT1MMKi6"
      },
      "source": [
        "## Complete your code here \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkhD1u25Ex9J"
      },
      "source": [
        "## Generate Datasets\n",
        "\n",
        "In the previous exercise, when we use `keras.datasets` to load the Fashion MNIST dataset, the data are already splitted to train and test(validation) set and are loaded as numpy array. However, if you are working with your own dataset, you will probably have a bunch of image files in a filesystem and you will need to do your train/test split. Also, if you have a large dataset, it is not efficient to make all the images loaded as numpy array, as you will probably run out of memory soon. A more efficient way is to use [`tf.data.Datasets`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) API to load the data (recommended way). \n",
        "\n",
        "Keras provides an easy-to-use function [image_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) that behaves like the old good [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) but uses the more efficient `tf.data.Datasets`\n",
        "\n",
        "You will need to organize your images into a folder structure like shown here. Assuming you have two classes A and B, your folder should look like below: \n",
        "\n",
        "```\n",
        "data\n",
        "  classA\n",
        "    imageA1.jpg\n",
        "    imageA2.jpg \n",
        "  classB\n",
        "    imageB1.jpg\n",
        "    imageB2.jpg\n",
        "```\n",
        "\n",
        "You can then use the following code to create a training dataset and validation dataset, both as tf.data.Dataset: \n",
        "\n",
        "```python\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOH6_TyoEx9J"
      },
      "source": [
        "# Complete your code here \n",
        "\n",
        "# specify the desired input size to the convolutional neural network\n",
        "image_size = (??, ??)\n",
        "\n",
        "# specify the training batch size\n",
        "batch_size = ??\n",
        "\n",
        "# use image_dataset_from_directory() to create both train and validation dataset\n",
        "train_ds = ?? \n",
        "\n",
        "val_ds = ?? "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_-T5V0dG9Kr"
      },
      "source": [
        "\n",
        "The label will be inferred from the name of the subdirectory `classA (label 0)` and `classB (label 1)`, where the numeric label is assigned according to alphanumeric order.   \n",
        "\n",
        "You can look at the assignment using the `class_names` variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sQy4NuRGlOn"
      },
      "source": [
        "train_ds.class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB86lOruEx9K"
      },
      "source": [
        "## Visualize sample images from your train or validation dataset\n",
        "\n",
        "Visualize some of the images in training dataset.  Also find out what label (0 or 1) is given to cat and dog respectively. You can use the `take(1)` method of `tf.data.Dataset` to take 1 batch of samples (image + label). You can then iterate over this to retrieve each sample. For example: \n",
        "\n",
        "```python\n",
        "for images, labels in train_ds.take(1): \n",
        "    for i in range(len(images): \n",
        "       ## do something \n",
        "       \n",
        "```\n",
        "\n",
        "You can also convert the dataset into a list if you prefer to work with list. For example: \n",
        "\n",
        "```python\n",
        "samples = list(train_ds.take(1))\n",
        "images, labels = samples[0]   \n",
        "\n",
        "```\n",
        "\n",
        "`samples[0]` is a tuple and the length of the images and labels is the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tgw94jREx9K"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# complete your code here\n",
        "\n",
        "# loop through one batch of samples and display them \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om3eCKWbWm8i"
      },
      "source": [
        "## Build your Model\n",
        "\n",
        "Build your model and compile your model with appropriate loss function and optimizer. You can choose any combination of layers and units but observe general design pattern (e.g. VGG-16). Also try to use the functional API instead of sequential API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo5I3C0rEx9L"
      },
      "source": [
        "## complete your code here, use functional API model\n",
        "\n",
        "model = ??\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGllb4wvWm8l"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Train your model. Specify the callbacks you want (e.g. Tensorboard, ModelCheckpoint, etc).  \n",
        "As you will be using `tf.data.Dataset` as your dataset, instead of images and labels arrays, you can call your `model.fit()` by simply \n",
        "`model.fit(train_ds, validation_data=val_ds, ....)` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uKL5rx_Ex9L"
      },
      "source": [
        "# Complete your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo9XVvMPWm8m"
      },
      "source": [
        "## Visualize the training and validation loss\n",
        "\n",
        "Visualize your training and validation loss. What do you observe? Is there any overfitting/underfitting problem? Modify your model to address the problem, if any."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSR5hMLsWm8n"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}